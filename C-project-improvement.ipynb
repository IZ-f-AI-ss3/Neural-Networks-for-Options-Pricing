{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: mps\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch.nn.functional as F\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "device = torch.device('cuda') if (USE_GPU and torch.cuda.is_available()) else torch.device('mps')\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## American Option Pricing with Multiple Neural Networks (method 1) article [1]\n",
    "Here I'll try a simple implementation of the method I of the first article :\n",
    "\n",
    "Here we have constant interest rate so the discount factor is $\\exp(-rT)$, and the stock dynamics are modelled with Geometric Brownian Motion (GBM).\n",
    "\n",
    "$\\large dS_t = rS_tdt+\\sigma S_tdW_t$\n",
    "\n",
    "Let's simulate this GBM process by simulating variables of the natural logarithm process of the stock price $x_t = ln(S_t)$, which is normally distributed. For the dynamics of the natural logarithm process of stock prices under GBM model you need to use Ito's calculus.\n",
    "$\\large dx_t = \\nu dt+\\sigma dW_t ,  \\nu = r - \\frac{1}{2} \\sigma ^ 2$\n",
    "\n",
    "We can then discretize the Stochastic Differential Equation (SDE) by changing the infinitesimals $dx, dt, dz$ into small steps $\\Delta x, \\Delta t, \\Delta W$.\n",
    "\n",
    "$\\large \\Delta x = \\nu  \\Delta t+\\sigma \\Delta W$\n",
    "\n",
    "This is the exact solution to the SDE and involves no approximation.\n",
    "\n",
    "$\\large x_{t+\\Delta t} = x_{t} + \\nu (\\Delta t)+\\sigma (W_{t+\\Delta t}- W_t)$\n",
    "\n",
    "In terms of the stock price S, we have:\n",
    "\n",
    "$\\large S_{t+\\Delta t} = S_{t} \\exp( \\nu \\Delta t + \\sigma (W_{t+\\Delta t}- W_t) )$\n",
    "\n",
    "Where $(W_{t+\\Delta t}- W_t) \\sim N(0,\\Delta t) \\sim \\sqrt{\\Delta t} N(0,1) \\sim \\sqrt{\\Delta t} \\epsilon_i$\n",
    "\n",
    "\n",
    "\\\\\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The algorithm :\n",
    "\n",
    "***Algorithm 1 :*** American Option Pricing with Multiple Neural Networks\n",
    "\n",
    "**Result :** Functions $\\Phi_{t_i}, \\Psi_{t_i}$ for $i \\in \\{0,1, \\ldots, n-1\\}$\n",
    "\n",
    "Simulate $N$ stock paths\n",
    "\n",
    "Initialize $Y_{t_n} = X_{t_n} = f\\left(S_{t_n}\\right)$\n",
    "\n",
    "for $i = n-1 : 1$ do  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; Regress $\\beta_{\\Delta t}^{-1} Y_{t_{i+1}}$ on $S_{t_i}$:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $\\min_{\\Phi_{t_i}, \\Psi_{t_i}}\\left(\\beta_{\\Delta t}^{-1} Y_{t_{i+1}} - \\Phi_{t_i}\\left(S_{t_i}\\right) - \\Psi_{t_i}\\left(S_{t_i}\\right) \\Delta W_{t_i}\\right)^2$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $Y_{t_i} = \\beta_{\\Delta t}^{-1} Y_{t_{i+1}} - \\Psi_{t_i}\\left(S_{t_i}\\right) \\Delta W_{t_i}$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $X_{t_i} = \\beta_{\\Delta t}^{-1} X_{t_{i+1}} - \\Psi_{t_i}\\left(S_{t_i}\\right) \\Delta W_{t_i}$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; if $f\\left(S_{t_i}\\right) > \\Phi_{t_i}\\left(S_{t_i}\\right)$ then  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $Y_{t_i} = f\\left(S_{t_i}\\right)$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; end  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; if $f\\left(S_{t_i}\\right) > X_{t_i}$ then  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; $X_{t_i} = f\\left(S_{t_i}\\right)$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; end  \n",
    "end\n",
    "\n",
    "Regress $\\beta_{\\Delta t}^{-1} Y_{t_1}$ on $S_{t_0}$:  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $\\min \\left(\\beta_{\\Delta t}^{-1} Y_{t_1} - \\Phi_{t_0}\\left(S_{t_0}\\right) - \\Psi_{t_0}\\left(S_{t_0}\\right) \\Delta W_{t_0}\\right)^2$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $Y_{t_0} = \\beta_{\\Delta t}^{-1} Y_{t_1} - \\Psi_{t_0}\\left(S_{t_0}\\right) \\Delta W_{t_0}$  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; $X_{t_0} = \\beta_{\\Delta t}^{-1} X_{t_1} - \\Psi_{t_0}\\left(S_{t_0}\\right) \\Delta W_{t_0}$  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class stochastic_models() :\n",
    "    def __init__(self, r, vol , S , K, T , dt , n , M) :\n",
    "        self.r  = r\n",
    "        self.vol =  vol\n",
    "        self.S = S\n",
    "        self.K = K\n",
    "        self.dt = dt\n",
    "        self.n = n\n",
    "        self.T = T\n",
    "        self.M = M\n",
    "        self.beta_dt = math.exp(-self.r*self.dt)\n",
    "\n",
    "        self.S_simulation = None\n",
    "        self.dW_simulation = None\n",
    "\n",
    "    def simulate_path(self , device ) :\n",
    "        nudt = (self.r - 0.5 * self.vol**2) * self.dt\n",
    "        lnS = np.log(self.S)\n",
    "\n",
    "        # Méthode de Monte Carlo\n",
    "        Z = np.random.normal(size=(self.M,self.n))\n",
    "        dW=np.sqrt(self.dt) * Z  #it's the simulation of the dWt_i we'll need in each iteration\n",
    "        delta_lnSt = nudt + self.vol*dW\n",
    "        LnS_s = np.zeros([self.M, self.n + 1])\n",
    "\n",
    "        for i in range(self.M):\n",
    "            LnS_s[i, 0] = lnS\n",
    "            for j in range(1, n + 1):\n",
    "                LnS_s[i, j] = LnS_s[i, j - 1] + delta_lnSt[i,j - 1]\n",
    "\n",
    "        S = np.exp(LnS_s)\n",
    "        S_tensor = torch.tensor(S, device = device ,dtype=dtype)\n",
    "        dW_tensor = torch.tensor(dW, device = device ,dtype=dtype)\n",
    "        self.S_simulation, self.dW_simulation =  S_tensor,dW_tensor\n",
    "        \n",
    "\n",
    "#Parametres\n",
    "T = 1\n",
    "n = 50\n",
    "dt = T/n  #les t_i seront donc les i*dt.\n",
    "\n",
    "\n",
    "S = 36          # Prix de l'action\n",
    "K = 40           # Prix d'exercice\n",
    "vol = 0.2       # Volatilité (%)\n",
    "r = 0.06            # Taux sans risque (%)\n",
    "M = 20000        # Nombre de simulations\n",
    "\n",
    "stochastic_model = stochastic_models(r = r, vol = vol, S = S, K = K, n = n , dt = dt , T = T , M = M)\n",
    "stochastic_model.simulate_path(device = device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  32%|███▏      | 16/50 [02:54<06:09, 10.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  38%|███▊      | 19/50 [03:21<05:09,  9.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  40%|████      | 20/50 [03:26<04:17,  8.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  42%|████▏     | 21/50 [03:32<03:40,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  46%|████▌     | 23/50 [03:47<03:34,  7.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  48%|████▊     | 24/50 [03:55<03:26,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  50%|█████     | 25/50 [04:01<03:05,  7.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  52%|█████▏    | 26/50 [04:10<03:08,  7.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  54%|█████▍    | 27/50 [04:16<02:44,  7.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  56%|█████▌    | 28/50 [04:23<02:39,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  58%|█████▊    | 29/50 [04:28<02:16,  6.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  60%|██████    | 30/50 [04:37<02:27,  7.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  62%|██████▏   | 31/50 [04:44<02:16,  7.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  64%|██████▍   | 32/50 [04:50<02:03,  6.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  66%|██████▌   | 33/50 [04:55<01:45,  6.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  70%|███████   | 35/50 [05:13<01:57,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  74%|███████▍  | 37/50 [05:31<01:50,  8.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  78%|███████▊  | 39/50 [05:48<01:36,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  80%|████████  | 40/50 [05:55<01:21,  8.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  82%|████████▏ | 41/50 [06:01<01:07,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  84%|████████▍ | 42/50 [06:07<00:58,  7.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  88%|████████▊ | 44/50 [06:27<00:52,  8.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  90%|█████████ | 45/50 [06:33<00:38,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  92%|█████████▏| 46/50 [06:39<00:28,  7.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  94%|█████████▍| 47/50 [06:47<00:22,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  96%|█████████▌| 48/50 [06:52<00:13,  6.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations:  98%|█████████▊| 49/50 [07:01<00:07,  7.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Early stopping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Iterations: 100%|██████████| 50/50 [07:10<00:00,  8.60s/it]\n"
     ]
    }
   ],
   "source": [
    "class IterationModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(IterationModel, self).__init__()\n",
    "        self.branch1 = nn.Sequential(\n",
    "            nn.Linear(1, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1)\n",
    "        )\n",
    "        self.branch2 = nn.Sequential(\n",
    "            nn.Linear(1, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1) ,          \n",
    "  \n",
    "        )\n",
    "        self.branch3 = nn.Sequential(\n",
    "            nn.Linear(1, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 40),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(40, 1) ,          \n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_branch1 = self.branch1(x)\n",
    "        x_branch2 = self.branch2(x)\n",
    "        x_branch3 = self.branch3(x)\n",
    "        \n",
    "        concatenated_output = torch.cat((x_branch1, x_branch2 , x_branch3), dim=1)\n",
    "        return concatenated_output\n",
    "\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, verbose=False, delta=0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n",
    "                            Default: 0\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.val_loss_min = np.Inf\n",
    "        self.delta = delta\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        score = -val_loss\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                pass\n",
    "                # print(f'EarlyStopping counter: {self.counter} out of {self.patience}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "\n",
    "\n",
    "\n",
    "class RecurrentNetworkModel(nn.Module) :\n",
    "    def __init__(self  , lr = 0.01 , device = device , stochastic_model = stochastic_model):\n",
    "        super(RecurrentNetworkModel, self).__init__()\n",
    "        self.model = IterationModel().to(device) \n",
    "        self.K = K\n",
    "        self.stochastic_model = stochastic_model\n",
    "        self.beta_dt = self.stochastic_model.beta_dt\n",
    "        self.K = self.stochastic_model.K\n",
    "        self.n_iterations = self.stochastic_model.n\n",
    "        self.optimizer =optim.Adam(self.model.parameters(), lr=lr) # type: ignore\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.S , self.dW =  self.stochastic_model.S_simulation, self.stochastic_model.dW_simulation\n",
    "\n",
    "\n",
    "\n",
    "    def custom_loss(self , Y_true, dW_true ,dW_true_2 , y_pred):\n",
    "        return  self.criterion(y_pred[:, 0] + dW_true * y_pred[:, 1] + (dW_true_2-dt)*y_pred[:, 2], Y_true)\n",
    "    \n",
    "    def eval_all(self, iter, S_iter, batch_size ,X,  Y , dW_iter ) :\n",
    "        X_new = []\n",
    "        Y_new = []\n",
    "\n",
    "        eval_dataset = TensorDataset(S_iter, dW_iter, X, Y)\n",
    "        eval_loader = DataLoader(eval_dataset, batch_size=batch_size, shuffle=False)\n",
    "        self.model.eval()\n",
    "        with torch.no_grad() :\n",
    "            if iter > 0 :\n",
    "                for S_batch, dW_batch, X_batch, Y_batch in eval_loader:\n",
    "                    Fi = self.model(S_batch.unsqueeze(1))\n",
    "                    Z_batch = F.relu(self.K- S_batch)  \n",
    "                    dW_batch_square = dW_batch*dW_batch\n",
    "                    Y_batch = torch.where(Z_batch> Fi[:,0], Z_batch, self.beta_dt*Y_batch-Fi[:,1]*dW_batch - Fi[:,2]*dW_batch_square)\n",
    "                    X_batch = torch.where(Z_batch> X_batch, Z_batch, self.beta_dt*X_batch-Fi[:,1]*dW_batch - Fi[:,2]*dW_batch_square) \n",
    "                    X_new.append(X_batch)\n",
    "                    Y_new.append(Y_batch)\n",
    "            else :\n",
    "                for S_batch, dW_batch, X_batch, Y_batch in eval_loader:\n",
    "                    Fi = self.model(S_batch.unsqueeze(1))\n",
    "                    Z_batch = F.relu(self.K- S_batch)  \n",
    "                    dW_batch_square = dW_batch*dW_batch\n",
    "                    Y_batch =  self.beta_dt*Y_batch-Fi[:,1]*dW_batch  - Fi[:,2]*dW_batch_square\n",
    "                    X_batch =  self.beta_dt*X_batch-Fi[:,1]*dW_batch  - Fi[:,2]*dW_batch_square\n",
    "                    X_new.append(X_batch)\n",
    "                    Y_new.append(Y_batch)\n",
    "        \n",
    "        X = torch.cat(X_new, dim=0)\n",
    "        Y = torch.cat(Y_new, dim=0)\n",
    "        return X, Y\n",
    "\n",
    "    def train(self ,batch_size  = 2000, batch_size_eval = 256 , num_epochs = 5 , valid_split = 0.2 , patience = 10) : \n",
    "        S , dW =  self. S, self.dW\n",
    "        X = F.relu(self.K- S[:,self.n_iterations])\n",
    "        Y = F.relu(self.K- S[:,self.n_iterations])\n",
    "        # early_stopping = EarlyStopping(patience=patience ,verbose=True)\n",
    "        train_size = int((1 - valid_split) * S.size(0))\n",
    "        val_size = S.size(0) - train_size\n",
    "        train_idxs, val_idxs = torch.utils.data.random_split(range(S.size(0)), [train_size, val_size])\n",
    "        write = True\n",
    "        for iter in tqdm(range(self.n_iterations-1,-1,-1), desc=\"Processing Iterations\") :\n",
    "            early_stopping = EarlyStopping(patience=patience ,verbose=True)\n",
    "\n",
    "            S_iter, dW_iter = S[:,iter], dW[:,iter]\n",
    "            S_iter_train, dW_iter_train = S_iter[train_idxs.indices], dW_iter[train_idxs.indices] \n",
    "            S_iter_valid, dW_iter_valid = S_iter[val_idxs.indices], dW_iter[val_idxs.indices] \n",
    "            Y_iter_train = Y[train_idxs.indices]\n",
    "            Y_iter_valid = Y[val_idxs.indices]\n",
    "\n",
    "            start = time.time()\n",
    "            iter_train_dataset = TensorDataset(S_iter_train, dW_iter_train, Y_iter_train)\n",
    "            iter_valid_dataset = TensorDataset(S_iter_valid, dW_iter_valid, Y_iter_valid)\n",
    "            train_loader = DataLoader(iter_train_dataset, batch_size=batch_size, shuffle=True)\n",
    "            valid_loader = DataLoader(iter_valid_dataset, batch_size=batch_size_eval, shuffle=False)\n",
    "            end = time.time()\n",
    "            gamma1 = end - start\n",
    "\n",
    "            start = time.time()\n",
    "            for _ in range(num_epochs) :\n",
    "                self.model.train()\n",
    "                for S_batch, dW_batch , Y_batch in train_loader :\n",
    "                    self.optimizer.zero_grad()\n",
    "                    Fi = self.model(S_batch.unsqueeze(1))\n",
    "                    loss = self.custom_loss(self.beta_dt*Y_batch,dW_batch, dW_batch*dW_batch, Fi)\n",
    "                    loss.backward()\n",
    "                    self.optimizer.step()\n",
    "\n",
    "                self.model.eval()\n",
    "                total_valid_loss = 0\n",
    "                with torch.no_grad() :\n",
    "                    for S_batch, dW_batch , Y_batch in valid_loader :\n",
    "                        Fi = self.model(S_batch.unsqueeze(1))\n",
    "                        loss = self.custom_loss(self.beta_dt*Y_batch,dW_batch, dW_batch*dW_batch, Fi)\n",
    "                        total_valid_loss += loss.item()\n",
    "\n",
    "                mean_valid_loss = total_valid_loss / len(valid_loader)\n",
    "                early_stopping(mean_valid_loss)\n",
    "                if early_stopping.early_stop:\n",
    "                    print(\"Early stopping\")\n",
    "                    break\n",
    "               \n",
    "                \n",
    "\n",
    "            end =  time.time()\n",
    "            gamma2 = end - start            \n",
    "            start = time.time()\n",
    "            X,Y = self.eval_all(iter, S_iter, batch_size_eval, X ,  Y , dW_iter ) \n",
    "            end =  time.time()\n",
    "            gamma3 = end - start\n",
    "            # if write :\n",
    "            #     print('data-loader part :', gamma1 )\n",
    "            #     print(f' {num_epochs} epochs :',gamma2 )\n",
    "            #     print(f' evall_all part  :', gamma3)\n",
    "            #     write = False\n",
    "         \n",
    "        u0 = torch.mean(X)\n",
    "        l0 = torch.mean(Y)\n",
    "        return u0.item(),l0.item()\n",
    "\n",
    "lr =  1e-3\n",
    "Reccurent_Model = RecurrentNetworkModel(lr = lr , device = device)\n",
    "num_epochs = 15\n",
    "batch_size = 1024\n",
    "batch_size_eval = 512\n",
    "\n",
    "u0,l0 = Reccurent_Model.train(batch_size  = batch_size,batch_size_eval = batch_size_eval , num_epochs = num_epochs, valid_split = 0.2 , patience = 5 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The diff I found  0.01656651496887207\n",
      "The diff they found in the article :  0.01249999999999929\n"
     ]
    }
   ],
   "source": [
    "print('The diff I found ', np.abs(u0-l0))\n",
    "print('The diff they found in the article : ' ,4.4887-4.4762)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".llm_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
